{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/bhanupratap/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Train Data\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [['The patient had major bleeding when admitted yesterday','Relevant','Yes'],\n",
    "             ['The patient was admitted on [DATE] and resides at [PLACE]','Non-Relevant','False'],\n",
    "             ['There was no bleeding observed in the patient since the prescription of medication.','Relevant','No'],\n",
    "             ['Since the surgery, minor clotting was observed in patients stomach.','Relevant','DK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences with the help of nltk word tokenizer\n",
    "train_data = [[word_tokenize(x[0]), x[1], x[2]] for x in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dicts(data_):\n",
    "    word_to_ix = {}\n",
    "    class_to_ix = {}\n",
    "    relevance_to_ix = {}\n",
    "    for each_ in data_:\n",
    "        tokens = list(each_[0])\n",
    "        for each_token in tokens:\n",
    "            if(each_token not in word_to_ix):\n",
    "                word_to_ix[each_token] = len(word_to_ix)\n",
    "    word_to_ix['<START>'] = len(word_to_ix)\n",
    "    word_to_ix['<END>'] = len(word_to_ix)\n",
    "    word_to_ix['<UNK>'] = len(word_to_ix)\n",
    "    word_to_ix['<PAD>'] = len(word_to_ix)\n",
    "    \n",
    "    relevance_to_ix['Non-Relevant'] = 0\n",
    "    relevance_to_ix['Relevant'] = 1\n",
    "    \n",
    "    class_to_ix['Yes'] = 0\n",
    "    class_to_ix['No'] = 1\n",
    "    class_to_ix['DK'] = 2\n",
    "    class_to_ix['False'] = 3\n",
    "    to_ix = {}\n",
    "    to_ix['word2ix'] = word_to_ix\n",
    "    to_ix['class2ix'] = class_to_ix\n",
    "    to_ix['relevance2ix'] = relevance_to_ix\n",
    "    return to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the required vocab dictionaries\n",
    "to_ix = prepare_dicts(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions below to batchify the datapoints\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(all_datapoints, to_ix):\n",
    "    main_sents = []\n",
    "    main_scores = []\n",
    "    main_relevances = []\n",
    "\n",
    "    for each_datapoint in all_datapoints:\n",
    "        main_sents.append(each_datapoint[0])\n",
    "        main_relevances.append(to_ix['relevance2ix'][each_datapoint[1]])\n",
    "        main_scores.append(to_ix['class2ix'][each_datapoint[2]])\n",
    "    sorted_sents, sorted_lens, descend_indices = get_sequence_doc(main_sents, to_ix, LIMIT_LEN=150)\n",
    "    sorted_scores = []\n",
    "    sorted_relevances = []\n",
    "    sorted_contexts = []\n",
    "    sorted_rel_weights = []\n",
    "    sorted_sc_weights = []\n",
    "    sorted_main_docs = []\n",
    "    \n",
    "    for ind in descend_indices:\n",
    "        sorted_scores.append(main_scores[ind])\n",
    "        sorted_relevances.append(main_relevances[ind])\n",
    "        \n",
    "    dict_ = {'sents':sorted_sents, \n",
    "            'lens':sorted_lens,\n",
    "            'scores':sorted_scores,\n",
    "            'relevances':sorted_relevances}\n",
    "    return dict_\n",
    "\n",
    "def get_sequence_doc(sentences, to_ix, LIMIT_LEN = 150):\n",
    "    max_len = 0\n",
    "    batch_sents = []\n",
    "    for each_sentence in sentences:\n",
    "        batch_sent = []\n",
    "        for x in each_sentence:\n",
    "            if(x not in to_ix['word2ix']):\n",
    "                batch_sent.append(to_ix['word2ix']['<UNK>'])\n",
    "            else:\n",
    "                batch_sent.append(to_ix['word2ix'][x])\n",
    "        if(len(batch_sent)>max_len):\n",
    "            max_len = len(batch_sent)\n",
    "        batch_sents.append(batch_sent)\n",
    "    if(max_len>LIMIT_LEN):\n",
    "        max_len = LIMIT_LEN\n",
    "    all_lens = [len(x[:max_len]) for x in batch_sents]\n",
    "    all_lens = [x+2 for x in all_lens]\n",
    "    batch_sents = [[to_ix['word2ix']['<START>']]+batch_sents[ind][:max_len]+[to_ix['word2ix']['<END>']]+[to_ix['word2ix']['<PAD>'] for x in range(max_len-len(batch_sents[ind]))] for ind in range(len(batch_sents))]\n",
    "\n",
    "    descend_indices = list(np.argsort(all_lens))\n",
    "    descend_indices.reverse()\n",
    "    sorted_sents = []\n",
    "    sorted_lens = []\n",
    "    for ind in descend_indices:\n",
    "        sorted_sents.append(batch_sents[ind])\n",
    "        sorted_lens.append(all_lens[ind])\n",
    "    return sorted_sents, sorted_lens, descend_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "- LSTM/Bi-LSTM encoder with dot attention for multi-class classification\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaranjoTut(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NaranjoTut, self).__init__()\n",
    "        '''\n",
    "            hidden_dim: To define the hidden dimensions of the LSTM encoder\n",
    "            ans_size: Number of answer classes\n",
    "            relevance_size: Number of relevance classes\n",
    "            vocab_size: Size of our token vocabulary\n",
    "            embed_dim: Dimension of vocab embeddings\n",
    "            bilstm_flag: Whether the LSTM encoder is bidirectional or not\n",
    "            layers: Number of LSTM or BiLSTM layer in the encoder\n",
    "            dropout: The dropout coefficient for our LSTM layers\n",
    "        '''\n",
    "        self.config = config\n",
    "        self.hidden_dim = config['hidden_dim']\n",
    "        self.ans_size = config['ans_size']\n",
    "        self.relevance_size = config['relevance_size']\n",
    "        self.vocab_size = config['vocab_size']\n",
    "        self.embed_dim = config['embed_dim']\n",
    "        self.hidden2relevance = nn.Linear(config['hidden_dim'], config['relevance_size'])\n",
    "        self.hidden2ans = nn.Linear(config['hidden_dim'], config['ans_size'])\n",
    "        \n",
    "        self.bilstm_flag = config['bilstm_flag']\n",
    "        self.layers=config['layers']\n",
    "        self.dropout=config['dropout']\n",
    "        \n",
    "        # defining the word embeddings\n",
    "        self.word_embeddings = nn.Embedding(self.vocab_size, self.embed_dim)\n",
    "        \n",
    "        # Defining the LSTM encoder\n",
    "        if(self.bilstm_flag):\n",
    "            self.lstm_word = nn.LSTM(self.embed_dim, int(self.hidden_dim/2), num_layers = self.layers,\n",
    "                                bidirectional=True, batch_first=True, dropout=self.dropout)\n",
    "        else:\n",
    "            self.lstm_word = nn.LSTM(self.embed_dim, self.hidden_dim, num_layers = self.layers,\n",
    "                                bidirectional=False, batch_first=True, dropout=self.dropout)\n",
    "        \n",
    "        self.attn_relevance = DotAttentionLayer(self.hidden_dim)\n",
    "    \n",
    "    def init_hidden(self, bilstm_flag, batch_size, layers, hidden_dim):\n",
    "        # num_layes, minibatch size, hidden_dim\n",
    "        if(bilstm_flag):\n",
    "            return (autograd.Variable(torch.FloatTensor(layers*2,\n",
    "                                                             batch_size,\n",
    "                                                             int(hidden_dim/2)).fill_(0)),\n",
    "                   autograd.Variable(torch.FloatTensor(layers*2,\n",
    "                                                            batch_size,\n",
    "                                                            int(hidden_dim/2)).fill_(0)))\n",
    "        else:\n",
    "            return (autograd.Variable(torch.FloatTensor(layers,\n",
    "                                                             batch_size,\n",
    "                                                             hidden_dim).fill_(0)),\n",
    "                   autograd.Variable(torch.FloatTensor(layers,\n",
    "                                                            batch_size,\n",
    "                                                            hidden_dim).fill_(0)))\n",
    "    \n",
    "    def forward(self, sent_inds, sent_lens):\n",
    "        # Getting the embeddings\n",
    "        embeds = self.word_embeddings(sent_inds)\n",
    "        \n",
    "        # Pack the whole batch and initialize the hidden and cell states for the LSTM encoder\n",
    "        packed = pack_padded_sequence(embeds, batch_lens, batch_first = True)\n",
    "        self.hidden_vals = self.init_hidden(self.bilstm_flag, embeds.shape[0], self.layers, self.hidden_dim)\n",
    "        \n",
    "        # Getting the hidden states from the encoder for each of the token\n",
    "        packed_output, self.hidden_vals = self.lstm_word(packed, self.hidden_vals)\n",
    "        lstm_out = pad_packed_sequence(packed_output, batch_first=True)[0]\n",
    "        \n",
    "        # Getting sequence representation by doing weighted summation\n",
    "        pad_op = self.attn_relevance((lstm_out,batch_lens))\n",
    "        \n",
    "        # Softmax probs for relevance classification\n",
    "        tag_space_rel = self.hidden2relevance(pad_op)\n",
    "        tag_space_rel = F.log_softmax(tag_space_rel,dim=1) \n",
    "        \n",
    "        # Softmax probs for answer classification\n",
    "        tag_space_ans = self.hidden2ans(pad_op)\n",
    "        tag_space_ans = F.log_softmax(tag_space_ans, dim=1) \n",
    "        \n",
    "        return tag_space_rel, tag_space_ans\n",
    "        \n",
    "class DotAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DotAttentionLayer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: (unpacked_padded_output: batch_size x seq_len x hidden_size, lengths: batch_size)\n",
    "        \"\"\"\n",
    "        inputs, lengths = input\n",
    "        batch_size, max_len, _ = inputs.size()\n",
    "        flat_input = inputs.contiguous().view(-1, self.hidden_size)\n",
    "        logits = self.W(flat_input).view(batch_size, max_len)\n",
    "        alphas = F.softmax(logits, dim=1)\n",
    "\n",
    "        # computing mask\n",
    "        idxes = torch.arange(0, max_len, out=torch.LongTensor(max_len)).unsqueeze(0)\n",
    "        mask = autograd.Variable((idxes<lengths.unsqueeze(1)).float())\n",
    "        alphas = alphas * mask\n",
    "        \n",
    "        # renormalize\n",
    "        alphas = alphas / torch.sum(alphas, 1).view(-1, 1)\n",
    "        output = torch.bmm(alphas.unsqueeze(1), inputs).squeeze(1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'hidden_dim' : 400,\n",
    "    'bilstm_flag': True,\n",
    "    'ans_size' : len(to_ix['class2ix']),\n",
    "    'relevance_size' : len(to_ix['relevance2ix']),\n",
    "    'vocab_size' : len(to_ix['word2ix']),\n",
    "    'embed_dim' : 180, \n",
    "    'layers':2, \n",
    "    'dropout':0.1, \n",
    "    'lr':0.01,\n",
    "    'weight_decay':1e-6,\n",
    "    'batch_size':2,\n",
    "    'alpha':0.5,\n",
    "    'model_name': 'AMIA_tutorial_'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Model, Loss function and Optimizer\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhanupratap/py3/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = NaranjoTut(model_config)\n",
    "loss_function = nn.NLLLoss(reduce=False)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                           lr=model_config['lr'], \n",
    "                           weight_decay=model_config['weight_decay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchifying 2 datapoints together\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "\n",
    "pred_rel = []\n",
    "actual_rel = []\n",
    "\n",
    "pred_sc = []\n",
    "actual_sc = []\n",
    "\n",
    "train_loss = 0\n",
    "\n",
    "batch = batchify(train_data[0:2], to_ix)\n",
    "batch_sents = autograd.Variable(torch.LongTensor(batch['sents']))\n",
    "batch_lens = autograd.Variable(torch.LongTensor(batch['lens']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing them through the model\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rel, score_ans = model(batch_sents, batch_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the relevance and answer predictions\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_relevance_score = autograd.Variable(torch.LongTensor(batch['relevances'])) \n",
    "val, inds = torch.max(score_rel, dim=1)\n",
    "pred_rel+=inds.tolist()\n",
    "actual_rel+=actual_relevance_score.tolist()\n",
    "\n",
    "actual_sc_score = autograd.Variable(torch.LongTensor(batch['scores']))\n",
    "val, inds = torch.max(score_ans, dim=1)\n",
    "pred_sc+=inds.tolist()\n",
    "actual_sc+=actual_sc_score.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Relevances [0, 1]\n",
      "Predicted Relevances [1, 1]\n",
      "--------------------\n",
      "Actual Answers [3, 0]\n",
      "Predicted Answers [0, 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Relevances\", actual_rel)\n",
    "print(\"Predicted Relevances\", pred_rel)\n",
    "print('--'*10)\n",
    "print(\"Actual Answers\", actual_sc)\n",
    "print(\"Predicted Answers\", pred_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Relevance and Answer Loss\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_loss = loss_function(score_rel, actual_relevance_score)\n",
    "sc_loss = loss_function(score_ans, actual_sc_score)\n",
    "\n",
    "## Multi-task Loss\n",
    "loss = model_config['alpha']*torch.sum(relevance_loss)+(1-model_config['alpha'])*torch.sum(sc_loss)\n",
    "train_loss+=loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2eb87c1e3148f5aa5c91ec6bc2dbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "train_sc_loss_list = []\n",
    "for epoch in tqdm(range(50)):\n",
    "    pred_rel = []\n",
    "    actual_rel = []\n",
    "\n",
    "    pred_sc = []\n",
    "    actual_sc = []\n",
    "\n",
    "    train_loss = 0\n",
    "    tot_sc_loss = 0\n",
    "    for ind in range(0,len(train_data), model_config['batch_size']):\n",
    "        batch = batchify(train_data[ind:ind+model_config['batch_size']], to_ix)\n",
    "        batch_sents = autograd.Variable(torch.LongTensor(batch['sents']))\n",
    "        batch_lens = autograd.Variable(torch.LongTensor(batch['lens']))\n",
    "        \n",
    "        score_rel, score_ans = model(batch_sents, batch_lens)\n",
    "\n",
    "        actual_relevance_score = autograd.Variable(torch.LongTensor(batch['relevances'])) \n",
    "        val, inds = torch.max(score_rel, dim=1)\n",
    "        pred_rel+=inds.tolist()\n",
    "        actual_rel+=actual_relevance_score.tolist()\n",
    "\n",
    "        actual_sc_score = autograd.Variable(torch.LongTensor(batch['scores']))\n",
    "        val, inds = torch.max(score_ans, dim=1)\n",
    "        pred_sc+=inds.tolist()\n",
    "        actual_sc+=actual_sc_score.tolist()\n",
    "\n",
    "        relevance_loss = loss_function(score_rel, actual_relevance_score)\n",
    "        sc_loss = loss_function(score_ans, actual_sc_score)\n",
    "\n",
    "        loss = model_config['alpha']*torch.sum(relevance_loss)+(1-model_config['alpha'])*torch.sum(sc_loss)\n",
    "        train_loss+=loss.item()\n",
    "        tot_sc_loss+=torch.sum(sc_loss).item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_sc_loss_list.append(tot_sc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Relevances [0, 1, 1, 1]\n",
      "Predicted Relevances [0, 1, 1, 1]\n",
      "--------------------\n",
      "Actual Answers [3, 0, 1, 2]\n",
      "Predicted Answers [3, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Relevances\", actual_rel)\n",
    "print(\"Predicted Relevances\", pred_rel)\n",
    "print('--'*10)\n",
    "print(\"Actual Answers\", actual_sc)\n",
    "print(\"Predicted Answers\", pred_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f466582acc0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f466303add8>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_sc_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
